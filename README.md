# PDF Extractor + Web Scraper + ETL

Este proyecto es una demostraciÃ³n de un pipeline ETL (Extract, Transform, Load) diseÃ±ado para procesar informaciÃ³n de diversas fuentes. Combina tÃ©cnicas de web scraping para recolectar datos de internet y herramientas de extracciÃ³n de texto y tablas de documentos PDF. Una vez extraÃ­dos, los datos son limpiados, estructurados y finalmente cargados en formatos accesibles como CSV y texto plano. Es una soluciÃ³n versÃ¡til para la automatizaciÃ³n de la recolecciÃ³n y preparaciÃ³n de datos.




![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4-green?style=for-the-badge)
![pdfplumber](https://img.shields.io/badge/pdfplumber-2.0-blue?style=for-the-badge)

## ğŸ¯ Objetivo
Demostrar capacidad real en:
- Web scraping con XPath/CSS + BeautifulSoup + lxml
- ExtracciÃ³n avanzada de texto y tablas de PDFs
- Proceso ETL completo (Extract â†’ Transform â†’ Load)
- Buenas prÃ¡cticas (estructura de proyecto, README claro, requirements, logging)

## ğŸ›  TecnologÃ­as utilizadas
- Python 3.11
- BeautifulSoup4 + lxml (para scraping)
- pdfplumber (para PDFs â€“ mÃ¡s fÃ¡cil y potente que pdfminer)
- Requests
- Pandas (limpieza ETL)
- JSON + CSV (output)

## ğŸ“ Estructura del proyecto

```
unumbio-demo-pdf-scraping-etl/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ scraper.py          # Web scraping demo
â”‚   â”œâ”€â”€ pdf_extractor.py    # ExtracciÃ³n de PDFs
â”‚   â””â”€â”€ etl_pipeline.py     # Proceso ETL completo
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”œâ”€â”€ sample.pdf      # â† Descarga aquÃ­ tu PDF de prueba
â”‚   â”‚   â””â”€â”€ sample_url.txt  # URLs a scrapear
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ scraped_data.json
â”‚       â”œâ”€â”€ extracted_text.txt
â”‚       â””â”€â”€ cleaned_data.csv
â””â”€â”€ logs/
â””â”€â”€ app.log
```


## ğŸš€ InstalaciÃ³n 

```bash
git clone https://github.com/TU-USUARIO/unumbio-demo-pdf-scraping-etl.git
cd unumbio-demo-pdf-scraping-etl
python -m venv venv
source venv/bin/activate    # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

# requirements.txt
```env
requests==2.32.3
beautifulsoup4==4.12.3
lxml==5.3.0
pdfplumber==0.11.0
pandas==2.2.3
```

# â–¶ï¸ CÃ³mo ejecutar
```python
# 1. Scraping demo
python src/scraper.py

# 2. PDF extractor demo
python src/pdf_extractor.py

# 3. ETL completo (scraping â†’ limpieza â†’ guardado)
python src/etl_pipeline.py
```

# ğŸ“¸ Resultados esperados

Carpeta data/output/ con archivos JSON, TXT y CSV limpios.   
Logs claros en logs/app.log.
